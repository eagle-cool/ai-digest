---
name: generate-post
description: Generates daily AI news digests from Miniflux RSS feeds (AI category). Publishes to GitHub Pages and notifies via Discord.
argument-hint: "[optional: date]"
disable-model-invocation: false
user-invocable: true
allowed-tools: Task, WebFetch, Read, Write, Bash(mkdir*), Bash(date*), Bash(ls*), Bash(node *), Bash(test *), Bash(docker *), Bash(git *), Bash(cp *), Bash(rm *)
---

# AI Digest â€” RSS-First AI News â†’ GitHub Pages

> **Source**: Miniflux RSS aggregator (AI category, ~30 feeds)
> **Strategy**: RSS for bulk retrieval, Agent for quality evaluation, WebFetch only for deep-reading
> **Publish**: GitHub Pages (Jekyll) + Discord notification
> **Language**: Traditional Chinese (ç¹é«”ä¸­æ–‡) - titles keep original English, summaries in Traditional Chinese

## Core Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Main Agent (Orchestrator)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ Phase 1  â”‚ â†’  â”‚ Phase 2  â”‚ â†’  â”‚ Phase 3  â”‚ â†’  â”‚ Phase 4  â”‚  â”‚
â”‚   â”‚ Fetch    â”‚    â”‚ Filter & â”‚    â”‚ Deep     â”‚    â”‚ Generate â”‚  â”‚
â”‚   â”‚ RSS Data â”‚    â”‚ Evaluate â”‚    â”‚ Read     â”‚    â”‚ Report   â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚                â”‚                â”‚                â”‚       â”‚
â”‚       â–¼                â–¼                â–¼                â–¼       â”‚
â”‚   Miniflux API    Agent scores    WebFetch top 3    Markdown     â”‚
â”‚   â†’ AI category   title/desc     articles only     + slug       â”‚
â”‚     (1 API call)   (no fetch)     (optional)                     â”‚
â”‚                                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚   â”‚ Phase 5  â”‚ â†’  â”‚ Phase 6  â”‚ â†’  â”‚ Phase 7  â”‚                  â”‚
â”‚   â”‚ Mark     â”‚    â”‚ Publish  â”‚    â”‚ Discord  â”‚                  â”‚
â”‚   â”‚ Read     â”‚    â”‚ Pages    â”‚    â”‚ Notify   â”‚                  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚       â”‚                â”‚                â”‚                        â”‚
â”‚       â–¼                â–¼                â–¼                        â”‚
â”‚   Miniflux API    git push â†’      Send URL +                    â”‚
â”‚   mark as read    GitHub Pages    summary text                   â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†• REST API (via client.mjs)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Miniflux         â”‚  â† AI category feeds (~30 sources)
â”‚   (always running) â”‚  â† Handles caching, dedup, parsing
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Phase 0: Load SOUL

Before starting any phase, **read `SOUL.md`** from the project root to load the author persona.

```yaml
Steps:
  1. Read SOUL.md from the project root (ai-digest/SOUL.md)
  2. Internalize the persona: identity, writing style, tone, attitude, dos & don'ts
  3. ALL written content (editorial intro, summaries, key points, why it matters, Discord message)
     must reflect the SOUL.md persona throughout
  4. The persona nickname must NEVER appear in published content
```

## Execution Process

### Phase 1: Fetch RSS Data

Retrieve unread entries from Miniflux **AI category only** (category_id = 3).

```yaml
Steps:
  0. Pre-flight: ensure Miniflux is running
     docker ps --filter name=miniflux --format '{{.Names}}' | grep -q miniflux
     - If NOT running: inform user to start Miniflux first, then verify with healthcheck:
       node ~/.claude/skills/miniflux/client.mjs healthcheck
  1. Determine target date (user argument or today via `date +%Y-%m-%d`)
  2. Create output directory: mkdir -p NewsReport/
  3. Calculate "after" timestamp (3 days before target date):
     # Use: date -v-3d +%s (macOS) or date -d '3 days ago' +%s (Linux)
  4. Fetch unread entries from Miniflux WITH category and time filter:
     node ~/.claude/skills/miniflux/client.mjs entries --status unread --limit 200 --category 3 --after <unix_timestamp> --direction desc
     â†’ IMPORTANT: Always use --category 3 to filter AI feeds only
     â†’ IMPORTANT: Always use --after to avoid pulling old imported articles
     â†’ Returns JSON: { total, count, entries: [{ id, title, url, feed, published, content_preview }] }
  5. If total == 0, check if Miniflux is healthy:
     node ~/.claude/skills/miniflux/client.mjs healthcheck
     - If unhealthy: report error and stop
     - If healthy but 0 entries: report "no new AI content today"
```

### Phase 2: Filter & Evaluate (Agent â€” metadata only)

The Agent evaluates entries based on title + content_preview (RSS description). No web fetching needed.

```yaml
Input: Array of entries from Phase 1 (title, url, feed, content_preview)

Agent Evaluation Criteria:
  Include (AI-focused topics):
    - LLM: Model releases, benchmarks, training techniques, fine-tuning, inference optimization
    - AI Agents: Agent frameworks, autonomous workflows, tool use, planning systems
    - AI Coding: AI-assisted development tools, code generation, IDE integrations
    - AI Products: ChatGPT, Claude, Gemini, Copilot, Cursor, and other AI SaaS
    - AI Research: Papers with practical implications, alignment research, safety
    - AI Industry: Funding, acquisitions, partnerships, regulatory developments
    - AI Infrastructure: GPU supply, cloud AI services, training clusters, MLOps
  Exclude:
    - Non-AI tech content (frontend, systems, DevOps, security)
    - Marketing puff / PR without substance
    - Crypto/Blockchain (unless AI-related)
    - Job postings / hiring announcements
    - Content older than 3 days

Deduplication:
  - Handled by Miniflux read/unread status (selected articles are marked read after report)
  - Title similarity check (>80% = duplicate)

Scoring (1-5):
  - 5: Major model release, breaking AI industry news, groundbreaking research
  - 4: High-quality AI technical deep-dive, significant product update
  - 3: Interesting AI content, useful AI tutorial or analysis
  - 2: Okay content, niche AI interest
  - 1: Low quality or barely relevant to AI

Output: Tiered selection for the digest:
  Tier 1 â€” ğŸŒŠ ä»Šæ—¥æµªé ­ (3 articles, score 4-5):
    - The day's biggest AI waves, will get deep-read + rich summaries
  Tier 2 â€” âš¡ è¡æµªå¿«å ± (8-12 articles, score 3-4):
    - Worth knowing, one-liner summaries only
  Tier 3 â€” ğŸ„ æ·±æ°´å€ (3-5 articles, score 3+):
    - Long-form AI essays, research papers, or deep-dives worth diving into

  Each entry includes:
    - title (original English)
    - url
    - feed_name
    - tier: 1 | 2 | 3
    - quality_score: 1-5
    - summary_hint: 1-sentence description from content_preview (ç¹é«”ä¸­æ–‡)
    - entry_id: Miniflux entry ID (for marking as read later)
```

### Phase 3: Deep Read (Tier 1 articles only)

Only the 3 Tier 1 (ğŸ”¥ ä»Šæ—¥ç„¦é») articles get deep-read for rich summaries.

```yaml
Strategy:
  - Deep-read ALL Tier 1 articles (3 articles)
  - Tier 2 and Tier 3 use content_preview only â€” no fetching
  - Maximum 3 deep-reads per run (cost control)

Method 1 â€” Miniflux fetch-content (preferred, zero-cost):
  node ~/.claude/skills/miniflux/client.mjs fetch-content <entry_id>
  â†’ Returns original article HTML content fetched by Miniflux

Method 2 â€” WebFetch fallback (if Miniflux fetch-content returns empty):
  Use WebFetch to read the article URL directly
  â†’ Agent extracts key information from the page

For each Tier 1 article, produce:
  - summary: 3-4 sentence summary (ç¹é«”ä¸­æ–‡), written like you just tried the thing and are telling a friend.
    Use first-person perspective where natural (ã€Œæˆ‘è©¦äº†ä¸€ä¸‹ã€ã€Œä»¥æˆ‘çš„è§€å¯Ÿã€).
    Balance excitement with substance â€” hype is cheap, insight is gold.
  - key_points: 2-3 key takeaways (ç¹é«”ä¸­æ–‡), punchy and direct
  - so_what: 1 sentence on "so what?" / broader impact (ç¹é«”ä¸­æ–‡), connecting to trends the reader cares about

For Tier 2 articles: 1 sentence with a dash of personality â€” not a boring rewrite of the title.
For Tier 3 articles: 1 sentence pitch on why it's worth the deep dive â€” sell the read, not the headline.
```

### Phase 4: Generate Report + Slug + SEO Title

```yaml
SEO Title Generation (ç¹é«”ä¸­æ–‡):
  - Capture the day's AI vibe in one punchy line â€” like a surfer describing today's waves
  - Must be specific and informative, NOT generic like "æ¯æ—¥ AI æ—¥å ±"
  - Include key model names, companies, or AI concepts from top articles
  - Tone: casual-confident, the kind of thing you'd text a friend
  - 20-40 characters, no date in title (date is in front matter)
  - Examples:
    - "GPT-5 å¤šæ¨¡æ…‹çœŸçš„çŒ›ã€Claude 4 Agent ç›´æ¥èµ·é£›"
    - "Llama 4 é–‹æºç‚¸å ´ã€OpenAI Agents SDK çµ‚æ–¼ä¾†äº†"
    - "Scaling Law è¦‹é ‚ä¹‹çˆ­ã€Gemini 3 æ‚„æ‚„ç™»å ´"

Slug Generation:
  - Based on the top 2-3 AI highlights of the day
  - Format: lowercase English, hyphen-separated, max 6 words
  - Examples:
    - "gpt5-multimodal-claude4-agents"
    - "llama4-opensource-openai-agents-sdk"
    - "dario-amodei-gemini3-ai-scaling"
  - The slug is used for both the filename and the Jekyll URL

Tags (only use relevant ones from this set):
  - llm, agents, ai-tools, ai-research, ai-industry, ai-safety, mlops, ai-coding

Output:
  - Directory: NewsReport/
  - Filename: YYYY-MM-DD-<slug>.md
  - Format: Standard Markdown with Jekyll front matter
  - Language: Traditional Chinese (titles keep original English)

Jekyll Front Matter (MUST be included at top of file):
  ---
  title: "<SEO Title>"
  date: YYYY-MM-DD
  description: "<50-80 å­—ç¹ä¸­æ‘˜è¦ï¼Œé©åˆ Google æœå°‹çµæœç‰‡æ®µ>"
  tags: [llm, agents, ...]  # only include relevant categories
  ---

Content Structure (after front matter):
  - NO H1 title â€” Jekyll front matter `title` already renders as the page heading
  - Editorial intro (2-3 sentences, ç¹ä¸­): like you're texting a friend about what's hot today.
    Use wave/surfing metaphors naturally. Set the vibe for the whole post.
    Example tone: "ä»Šå¤© AI åœˆçš„æµªæœ‰é»çŒ›â€”â€”OpenAI ä¸Ÿäº†å€‹å¤§çš„å‡ºä¾†ï¼ŒGoogle ä¹Ÿä¸ç”˜ç¤ºå¼±ã€‚ä½†æœ€è®“æˆ‘èˆˆå¥®çš„å…¶å¯¦æ˜¯..."
  - ğŸŒŠ ä»Šæ—¥æµªé ­ (3 articles): deep coverage, first-person perspective, share your take
  - âš¡ è¡æµªå¿«å ± (8-12 articles): one-liner each, scannable, with personality
  - ğŸ„ æ·±æ°´å€ (3-5 articles): long-form worth diving into, sell the read
  - NO mention of RSS, Miniflux, feeds, or aggregation in published content
  - NO "execution mode" or "version" info â€” this is editorial content, not a system report
```

### Phase 5: Mark Read

```yaml
Steps:
  1. Mark all selected entries as read in Miniflux:
     node ~/.claude/skills/miniflux/client.mjs mark-read <id1,id2,id3,...>
```

### Phase 6: Publish to GitHub Pages

This skill runs inside the ai-digest Jekyll repo. Posts are written directly to `_posts/`.

```yaml
GitHub Pages URL base: https://eagle-cool.github.io/ai-digest

Steps:
  1. Copy report to Jekyll _posts directory:
     cp "NewsReport/YYYY-MM-DD-<slug>.md" "_posts/YYYY-MM-DD-<slug>.md"
  2. Pull, commit, and push:
     git add -A && git commit -m "YYYY-MM-DD: <slug>" && git pull --rebase && git push
  4. Construct page URL:
     https://eagle-cool.github.io/ai-digest/posts/<slug>/
  5. Wait 30 seconds for GitHub Pages to build, then verify once with WebFetch:
     - If live: proceed to Phase 7
     - If not live: proceed to Phase 7 anyway (typically builds within 30s)
```

### Phase 7: Discord Notification

```yaml
Steps:
  1. Check .env exists (if not: skip, inform user)
  2. Compose message (ç¹é«”ä¸­æ–‡, max 1800 chars):
     - Page URL
     - Top 3 highlights + 3 notable items
  3. Send text message (no file attachment):
     node ~/.claude/skills/discord-send/send.mjs ai-digest --text "<message>"
  4. Best-effort: failure does not affect report
```

**Discord message template:**

```
ğŸŒŠ <SEO Title>

ä»Šæ—¥æµªé ­
â€¢ [æ¨™é¡Œ] â€” ä¸€å¥è©±æ‘˜è¦ï¼ˆå¸¶è§€é»ï¼‰
â€¢ [æ¨™é¡Œ] â€” ä¸€å¥è©±æ‘˜è¦
â€¢ [æ¨™é¡Œ] â€” ä¸€å¥è©±æ‘˜è¦

âš¡ å¦æœ‰ N å‰‡å¿«å ± + N ç¯‡æ·±æ°´å€

ğŸ„ <URL>
```

## Output Template

```markdown
---
title: "<SEO Title>"
date: YYYY-MM-DD
description: "<50-80 å­—æ‘˜è¦ï¼Œç”¨çŸ½è°·æµªäººå£å»ï¼Œé©åˆæœå°‹çµæœç‰‡æ®µ>"
tags: [llm, agents]
---

ä»Šå¤© AI çš„æµªæœ‰é»çŒ›â€”â€”...(2-3 å¥é–‹å ´ï¼Œåƒåœ¨è·Ÿæœ‹å‹åˆ†äº«ä»Šå¤©çœ‹åˆ°æœ€ç‚¸çš„æ±è¥¿ã€‚è‡ªç„¶å¸¶å‡ºä¸»é¡Œï¼Œä¸è¦åˆ—èˆ‰å¼ã€‚)

---

## ğŸŒŠ ä»Šæ—¥æµªé ­

### [Article Title](URL)

3-4 å¥ï¼Œç”¨ã€Œæˆ‘çœ‹äº†ä¸€ä¸‹ã€ã€Œé€™æ±è¥¿çš„å²å®³ä¹‹è™•åœ¨æ–¼ã€çš„å£å»ã€‚ä¸åªèªªç™¼ç”Ÿäº†ä»€éº¼ï¼Œæ›´è¦èªªä½ æ€éº¼çœ‹ã€å°æˆ‘å€‘æœ‰ä»€éº¼å½±éŸ¿ã€‚å¯ä»¥èˆˆå¥®ï¼Œä½†è¦æœ‰æ ¹æ“šã€‚

**ç‚ºä»€éº¼é€™é“æµªå€¼å¾—è¿½ï¼š**
- é‡é»ä¸€ï¼ˆå¸¶è§€é»ï¼‰
- é‡é»äºŒ
- å°é–‹ç™¼è€…/ä½¿ç”¨è€…çš„å¯¦éš›å½±éŸ¿

### [Article Title](URL)

ï¼ˆåŒä¸Šæ ¼å¼ï¼Œå…± 3 ç¯‡æµªé ­æ–‡ç« ï¼‰

---

## âš¡ è¡æµªå¿«å ±

- **[Article Title](URL)** â€” ä¸€å¥è©±å¸¶éï¼Œä½†è¦æœ‰å€‹äººè§€æ„Ÿï¼Œä¸æ˜¯å†·å†°å†°çš„æ‘˜è¦
- **[Article Title](URL)** â€” å¯ä»¥å¸¶é»æƒ…ç·’ï¼šé©šå–œã€åæ§½ã€æœŸå¾…éƒ½è¡Œ
- **[Article Title](URL)** â€” è®“è®€è€…æƒä¸€çœ¼å°±çŸ¥é“è¦ä¸è¦é»é€²å»
- ...ï¼ˆå…± 8-12 å‰‡ï¼‰

---

## ğŸ„ æ·±æ°´å€

- **[Article Title](URL)** â€” ç”¨ä¸€å¥è©±è³£é€™ç¯‡æ–‡ç« ï¼šç‚ºä»€éº¼å€¼å¾—èŠ± 15 åˆ†é˜è®€
- **[Article Title](URL)** â€” é»å‡ºé€™ç¯‡çš„ç¨ç‰¹ä¹‹è™•ï¼Œä¸æ˜¯é‡è¤‡æ¨™é¡Œ
- ...ï¼ˆå…± 3-5 å‰‡ï¼‰
```

## Constraints & Principles

1. **RSS-First**: Always use Miniflux API for data retrieval. Never scrape source websites for listing.
2. **AI Category Only**: Always filter by `--category 3` to get AI feeds only.
3. **Agent for Evaluation Only**: Agent reads title/description to score and filter. No web fetching for listing.
4. **Deep Read = Selective**: Only top 3 articles with score >= 4 get full content fetch. Use Miniflux `fetch-content` first, WebFetch as fallback.
5. **Cost Control**: Target < 10K agent tokens per run.
6. **Mark as Read**: Always mark selected entries as read in Miniflux after report generation.
7. **SEO-Quality Output**: Every published article must have a compelling title, meta description, and meaningful URL slug. Write in the voice defined by SOUL.md, not like a bot.
8. **No Implementation Leaks**: Published content must NEVER mention RSS, Miniflux, feeds, aggregation, or any internal tooling.
9. **Meaningful Slugs**: Generate descriptive English slugs from the day's top AI highlights for readable URLs.
10. **Tiered Structure**: 3 æµªé ­ + 8-12 å¿«å ± + 3-5 æ·±æ°´å€ã€‚æµªé ­è¦è¡ã€å¿«å ±è¦å¿«ã€æ·±æ°´å€è¦æœ‰æ½›ä¸‹å»çš„åƒ¹å€¼ã€‚
11. **Language Consistency**: Summaries in ç¹é«”ä¸­æ–‡, titles and keywords in English.

## Error Handling

| Error | Handling |
|-------|---------|
| Miniflux unreachable | Run healthcheck, report error, stop |
| 0 unread entries | Report "no new AI content", skip report generation |
| fetch-content empty | Fallback to WebFetch for that article |
| WebFetch fails | Use content_preview only, note in report |
| git push fails | Report error, report still saved locally in NewsReport/ |
| GitHub Pages not live after 2 min | Send Discord with URL anyway (will be live shortly) |
| Discord send fails | Log error, do not affect report |
